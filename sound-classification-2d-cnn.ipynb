{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic library imports\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pandas setting \n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.options.display.max_rows = 5000\n",
    "\n",
    "# encoding the classes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# librosa for audion feature extraction\n",
    "import librosa\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plotly libraries\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly_express as px\n",
    "\n",
    "\n",
    "# keras components for constructing the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import (Dense, Input, Dropout, Convolution2D, \n",
    "MaxPool2D, GlobalMaxPool2D, GlobalAveragePooling2D, concatenate)\n",
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio file length and batch size for generator\n",
    "sampling_freq = 16000\n",
    "duration = 4\n",
    "input_length = sampling_freq*duration\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input target mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_target(base_data_path = 'data/'):\n",
    "\n",
    "    # audio files and their corresponding labels\n",
    "    train_path = base_data_path + \"train/Train/*.wav\"\n",
    "    train_label_path = base_data_path +  \"train.csv\"\n",
    "    test_path =  base_data_path + \"test/Test/*.wav\"\n",
    "\n",
    "    # input\n",
    "    train_files = glob.glob(train_path)\n",
    "    train_files = pd.DataFrame({'train_file_paths': train_files})\n",
    "    train_files['ID'] = train_files['train_file_paths'].apply(lambda x:x.split('/')[-1].split('.')[0])\n",
    "    train_files['ID'] = train_files['ID'].astype(int)\n",
    "    train_files = train_files.sort_values(by='ID')\n",
    "    test_files = glob.glob(test_path)\n",
    "\n",
    "    # target\n",
    "    train_labels = pd.read_csv(train_label_path)\n",
    "    train_file_to_label = train_files.merge(train_labels, on= \"ID\", how='inner')\n",
    "\n",
    "    # encoding the classes\n",
    "    int_encode = LabelEncoder()\n",
    "    train_file_to_label['class_int_encode'] = int_encode.fit_transform(train_file_to_label['Class'])\n",
    "    \n",
    "    \n",
    "    return train_file_to_label\n",
    "\n",
    "\n",
    "def audio_normalization(data):\n",
    "    \n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+0.0001)\n",
    "    return data-0.5\n",
    "\n",
    "input_length = 16000*4\n",
    "\n",
    "batch_size = 32\n",
    "n_mels = 320\n",
    "\n",
    "def mel_spectrum_db(audio, sample_rate=16000, window_size=20, #log_specgram\n",
    "                 step_size=10, eps=1e-10):\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels= n_mels)\n",
    "    mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40)/40\n",
    "\n",
    "    return mel_db.T\n",
    "\n",
    "\n",
    "def stretch(data, rate=1):\n",
    "\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    if len(data)>input_length:\n",
    "        data = data[:input_length]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def pitch_shift(data, n_steps=3.0):\n",
    "\n",
    "    data = librosa.effects.pitch_shift(data, sr=input_length, n_steps=n_steps)\n",
    "    if len(data)>input_length:\n",
    "        data = data[:input_length]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loguniform(low=0.00000001, high=0.01):\n",
    "    return np.exp(np.random.uniform(np.log(low), np.log(high)))\n",
    "\n",
    "\n",
    "def white(N, state=None):\n",
    "    \"\"\"\n",
    "    White noise.\n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    White noise has a constant power density. It's narrowband spectrum is therefore flat.\n",
    "    The power in white noise will increase by a factor of two for each octave band,\n",
    "    and therefore increases with 3 dB per octave.\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "def augment(data):\n",
    "    if np.random.uniform(0, 1)>0.95:\n",
    "        wnoise = loguniform()\n",
    "        data = data + wnoise*white(len(data))\n",
    "    if np.random.uniform(0, 1)>0.95:\n",
    "        stretch_val = np.random.uniform(0.9, 1.1)\n",
    "        data = stretch(data, stretch_val)\n",
    "    if np.random.uniform(0, 1)>0.95:\n",
    "        pitch_shift_val = np.random.uniform(-6, 6)\n",
    "        data = pitch_shift(data, n_steps=pitch_shift_val)\n",
    "    return data\n",
    "\n",
    "def load_audio_file(file_path, input_length=input_length):\n",
    "    data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
    "    if len(data)>input_length:\n",
    "        \n",
    "        \n",
    "        max_offset = len(data)-input_length\n",
    "        \n",
    "        offset = np.random.randint(max_offset)\n",
    "        \n",
    "        data = data[offset:(input_length+offset)]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if input_length > len(data):\n",
    "            max_offset = input_length - len(data)\n",
    "\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0\n",
    "        \n",
    "        \n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        \n",
    "    data = augment(data)\n",
    "    data = mel_spectrum_db(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def generator(file_paths, target_labels, batch_size=32):\n",
    "    while True:\n",
    "        file_paths, target_labels = shuffle(file_paths, target_labels)\n",
    "        \n",
    "        for batch_files, batch_labels in zip(chunker(file_paths, size=batch_size),\n",
    "                                             chunker(target_labels, size= batch_size)):\n",
    "\n",
    "            batch_data = [load_audio_file(fpath) for fpath in batch_files]\n",
    "            batch_data = np.array(batch_data)[:,:,:,np.newaxis]\n",
    "\n",
    "            \n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_file_paths</th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "      <th>class_int_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/Train/0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/Train/1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/Train/2.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/Train/3.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/Train/4.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_file_paths  ID         Class  class_int_encode\n",
       "0  data/train/Train/0.wav  0   siren         8               \n",
       "1  data/train/Train/1.wav  1   street_music  9               \n",
       "2  data/train/Train/2.wav  2   drilling      4               \n",
       "3  data/train/Train/3.wav  3   siren         8               \n",
       "4  data/train/Train/4.wav  4   dog_bark      3               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_to_label = input_to_target()\n",
    "train_file_to_label.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-d conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_model(input_shape = (126, 320, 1), nclass = 10):\n",
    "       \n",
    "    input_wave = Input(shape=input_shape)\n",
    "\n",
    "    xception = Xception(input_shape=(126, 320, 1), weights=None, include_top=False)\n",
    "\n",
    "    x = xception(input_wave)\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "\n",
    "    x = Dense(128, activation=activations.relu)(x)\n",
    "    x = Dense(nclass, activation=activations.softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=input_wave, outputs=x)\n",
    "    opt = optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def generator(file_paths, target_labels, batch_size=batch_size):\n",
    "    while True:\n",
    "        file_paths, target_labels = shuffle(file_paths, target_labels)\n",
    "        \n",
    "        for batch_files, batch_labels in zip(chunker(file_paths, size=batch_size),\n",
    "                                             chunker(target_labels, size= batch_size)):\n",
    "                                             \n",
    "            batch_data = [load_audio_file(fpath) for fpath in batch_files]\n",
    "            batch_data = np.array(batch_data)[:,:,:, np.newaxis]\n",
    "            \n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_audio(train_files, train_labels,\n",
    "                val_files, val_labels, input_shape = (126,320,1),nclass = 10, epochs = 20):\n",
    "    \n",
    "    model = build_2d_model(input_shape=(126,320,1), nclass=n_class)\n",
    "    \n",
    "    model.fit_generator(generator(train_files, train_labels), \n",
    "                        steps_per_epoch=len(train_files)//batch_size, epochs=epochs,\n",
    "\n",
    "                        validation_data=generator(val_files, val_labels), \n",
    "                        validation_steps=len(val_files)//batch_size,\n",
    "                        use_multiprocessing=True, max_queue_size=1,\n",
    "                        callbacks=[ModelCheckpoint(\"models/baseline_cnn.h5\",\n",
    "                                                   monitor=\"val_acc\", save_best_only=True),\n",
    "                                   EarlyStopping(patience=5, monitor=\"val_acc\")])\n",
    "\n",
    "\n",
    "    model.save_weights(\"models/baseline_cnn.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 126, 320, 1)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 4, 10, 2048)       20860904  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_4 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 21,124,466\n",
      "Trainable params: 21,069,938\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node xception_4/block1_conv1/Conv2D}}]]\n\t [[loss_4/dense_9_loss/sparse_categorical_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_2523/has_valid_nonscalar_shape/then/_5254/has_invalid_dims/concat/_348]] [Op:__inference_keras_scratch_graph_76975]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b5daa004967b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m train_audio(train_files, train_labels,\n\u001b[0;32m---> 13\u001b[0;31m                 val_files, val_labels, nclass = 10, epochs = 20)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-d9a2287b6ad7>\u001b[0m in \u001b[0;36mtrain_audio\u001b[0;34m(train_files, train_labels, val_files, val_labels, input_shape, nclass, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         callbacks=[ModelCheckpoint(\"models/baseline_cnn.h5\",\n\u001b[1;32m     13\u001b[0m                                                    monitor=\"val_acc\", save_best_only=True),\n\u001b[0;32m---> 14\u001b[0;31m                                    EarlyStopping(patience=5, monitor=\"val_acc\")])\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node xception_4/block1_conv1/Conv2D}}]]\n\t [[loss_4/dense_9_loss/sparse_categorical_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_2523/has_valid_nonscalar_shape/then/_5254/has_invalid_dims/concat/_348]] [Op:__inference_keras_scratch_graph_76975]"
     ]
    }
   ],
   "source": [
    "input_files = train_file_to_label['train_file_paths']\n",
    "target_labels = train_file_to_label['class_int_encode']\n",
    "\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(input_files, target_labels,\n",
    "                                                                    test_size=0.15, random_state=42)\n",
    "train_files = train_files.values\n",
    "val_files = val_files.values\n",
    "train_labels = train_labels.values\n",
    "val_labels = val_labels.values\n",
    "n_class= len(train_file_to_label['Class'].unique())\n",
    "\n",
    "train_audio(train_files, train_labels,\n",
    "                val_files, val_labels, nclass = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_audio(test_files, list_labels):\n",
    "    bag = 5\n",
    "    array_preds = 0\n",
    "\n",
    "    for i in tqdm(range(bag)):\n",
    "\n",
    "        list_preds = []\n",
    "\n",
    "        for batch_files in tqdm(chunker(test_files, size=batch_size), total=len(test_files)//batch_size ):\n",
    "            batch_data = [load_audio_file(fpath) for fpath in batch_files]\n",
    "            batch_data = np.array(batch_data)[:,:,np.newaxis]\n",
    "            preds = model.predict(batch_data).tolist()\n",
    "            list_preds += preds\n",
    "\n",
    "\n",
    "        array_preds += np.array(list_preds)/bag\n",
    "\n",
    "    list_labels = np.array(list_labels)\n",
    "\n",
    "    top_5 = list_labels[np.argsort(-array_preds, axis=1)[:, :5]]\n",
    "    pred_labels = [' '.join(list(x)) for x in top_5]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(test_files, columns=[\"file_name\"])\n",
    "    df['label'] = pred_labels\n",
    "    df['file_name'] = df['file_name'].apply(lambda x: x.split(\"/\")[-1])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_path = 'data/'\n",
    "test_path =  base_data_path + \"test/Test/*.wav\"\n",
    "test_files = glob.glob(test_path)[0:3]\n",
    "list_labels = train_file_to_label['Class'].unique().tolist()\n",
    "test_audio(test_files, list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
